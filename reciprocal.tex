%
% Copyright © 2020 Peeter Joot.  All Rights Reserved.
% Licenced as described in the file LICENSE under the root directory of this GIT repository.
%
%{
\input{../latex/blogpost.tex}
\renewcommand{\basename}{reciprocal}
%\renewcommand{\dirname}{notes/phy1520/}
\renewcommand{\dirname}{notes/ece1228-electromagnetic-theory/}
%\newcommand{\dateintitle}{}
%\newcommand{\keywords}{}

\input{../latex/peeter_prologue_print2.tex}

\usepackage{amsthm}
\usepackage{peeters_layout_exercise}
\usepackage{peeters_braket}
\usepackage{peeters_figures}
\usepackage{siunitx}
\usepackage{verbatim}
%\usepackage{mhchem} % \ce{}
%\usepackage{macros_bm} % \bcM
%\usepackage{macros_qed} % \qedmarker
%\usepackage{txfonts} % \ointclockwise

\beginArtNoToc

\generatetitle{Reciprocal frame and curvilinear coordinates.}
%\chapter{Reciprocal frame uniqueness}
%\label{chap:reciprocal}

\section{Motivation.}
When studying curvilinear coordinates, reciprocal frame vectors are found to be the gradients of the parameters generating the tangent space at the point of evaluation.  We can also construct reciprocal frame vectors algebraically, but have a uniqueness doing so unless additional constraints are imposed.
In particular, the coordinates of a vector can be computed with respect to either the tangent space basis, or it's reciprocal basis, so we must impose the constraint that the reciprocal frame is restricted to the span of the tangent space basis.  Failing to impose such a constraint leads to uniqueness problems, and almost certainly means that the algebraic construction does not match the gradient construction.

In these notes, I'll walk through all the ideas involved.  The focus will be on the Dirac's algebra of special relativity, known as STA (Space Time Algebra) in geometric algebra parlance.

\paragraph{On notation.}
In Euclidean space we use bold face reciprocal frame vectors \( \Bx^i \cdot \Bx_j = {\delta^i}_j \), which nicely distinguishes them from the generalized coordinates \( x_i, x^j \) associated with the basis or the reciprocal frame, that is
\begin{equation}\label{eqn:reciprocal:640}
\Bx = x^i \Bx_i = x_j \Bx^j.
\end{equation}
On the other hand, it is conventional to use non-bold face for both the four-vectors and their coordinates in STA, such as the following standard basis decomposition
\begin{equation}\label{eqn:reciprocal:660}
x = x^\mu \gamma_\mu = x_\mu \gamma^\mu.
\end{equation}
If we use non-bold face \( x^\mu, x_\nu \) for the coordinates with respect to a specified frame, then we cannot also use non-bold face for the curvilinear basis vectors.
%One way to solve this notational problem would be to choose some new symbol, say \( f^\mu, f_\nu \), for our curvilinear basis vectors.
%This seems like a grossly arbitrary choice.  Symbols that are generally available without some additional or conflicting meaning can be hard to come by, so I'll opt to
To resolve this notational ambiguity, I've chosen to use bold face \( \Bx^\mu, \Bx_\nu \) symbols as the curvilinear basis elements in this relativistic context, as we do for Euclidean spaces.
\section{Basis and coordinates.}
\makedefinition{Standard Dirac basis.}{dfn:reciprocal:720}{
The Dirac basis elements are \(\setlr{ \gamma_0, \gamma_1, \gamma_2, \gamma_3 } \), satisfying
\begin{equation*}
\gamma_0^2 = 1 = -\gamma_k^2, \quad \forall k = 1,2,3,
\end{equation*}
and
\begin{equation}\label{eqn:reciprocal:740}
\gamma_\mu \cdot \gamma_\nu = 0, \quad \forall \mu \ne \nu.
\end{equation}
} % definition
A conventional way of summarizing these orthogonality relationships is \( \gamma_\mu \cdot \gamma_\nu = \eta_{\mu\nu} \), where
\( \eta_{\mu\nu} \) are the elements of the metric \( G = \diag(+,-,-,-) \).
\makedefinition{Reciprocal basis for the standard Dirac basis.}{dfn:reciprocal:760}{
We define a reciprocal basis \( \setlr{ \gamma^0, \gamma^1, \gamma^2, \gamma^3} \) satisfying \( \gamma^\mu \cdot \gamma_\nu = {\delta^\mu}_\nu, \forall \mu,\nu \in 0,1,2,3 \).
} % definition
\maketheorem{Reciprocal basis uniqueness.}{thm:reciprocal:780}{
This reciprocal basis is unique, and for our choice of metric has the values
\begin{equation*}
\gamma^0 = \gamma_0, \quad \gamma^k = -\gamma_k, \quad \forall k = 1,2,3.
\end{equation*}
} % theorem
Proof is left to the reader.
\makedefinition{Coordinates.}{dfn:reciprocal:800}{
We define the coordinates of a vector with respect to the standard basis as \( x^\mu \) satisfying
\begin{equation*}
x = x^\mu \gamma_\mu,
\end{equation*}
and define the coordinates of a vector with respect to the reciprocal basis as \( x_\mu \) satisfying
\begin{equation*}
x = x_\mu \gamma^\mu,
\end{equation*}
} % definition
\maketheorem{Coordinates.}{thm:reciprocal:820}{
Given the definitions above, we may compute the coordinates of a vector, simply by dotting with the basis elements
\begin{equation*}
x^\mu = x \cdot \gamma^\mu,
\end{equation*}
and
\begin{equation*}
x_\mu = x \cdot \gamma_\mu,
\end{equation*}
} % theorem
\begin{proof}
This follows by straightforward computation
\begin{dmath}\label{eqn:reciprocal:840}
x \cdot \gamma^\mu
=
\lr{ x^\nu \gamma_\nu } \cdot \gamma^\mu
=
x^\nu \lr{ \gamma_\nu \cdot \gamma^\mu }
=
x^\nu {\delta_\nu}^\mu
=
x^\mu,
\end{dmath}
and
\begin{dmath}\label{eqn:reciprocal:860}
x \cdot \gamma_\mu
=
\lr{ x_\nu \gamma^\nu } \cdot \gamma_\mu
=
x_\nu \lr{ \gamma^\nu \cdot \gamma_\mu }
=
x_\nu {\delta^\nu}_\mu
=
x_\mu.
\end{dmath}
\end{proof}
\section{Derivative operators.}
We'd like to determine the form of the (spacetime) gradient operator.  The gradient can be defined in terms of coordinates directly, but we choose an implicit definition, in terms of the directional derivative.
\makedefinition{Directional derivative and gradient.}{dfn:reciprocal:880}{
Let \( F = F(x) \) be a four-vector parameterized multivector.  The directional derivative of \( F \) with respect to the (four-vector) direction \( a \) is denoted
\begin{equation*}
\lr{ a \cdot \grad } F = \lim_{\epsilon \rightarrow 0} \frac{ F(x + \epsilon a) - F(x) }{ \epsilon },
\end{equation*}
where \( \grad \) is called the space time gradient.
} % definition
\maketheorem{Gradient.}{thm:reciprocal:900}{
The standard basis representation of the gradient is
\begin{equation*}
\grad = \gamma^\mu \partial_\mu,
\end{equation*}
where
\begin{equation*}
\partial_\mu = \PD{x^\mu}{}.
\end{equation*}
} % theorem
\begin{proof}
The Dirac gradient pops naturually out of the coordinate representation of the directional derivative, as we can see by
expanding \( F(x + \epsilon a) \) in Taylor series
\begin{dmath}\label{eqn:reciprocal:900}
F(x + \epsilon a)
= F(x) + \epsilon \frac{dF(x + \epsilon a)}{d\epsilon} + O(\epsilon^2)
= F(x) + \epsilon \PD{\lr{x^\mu + \epsilon a^\mu}}{F} \PD{\epsilon}{\lr{x^\mu + \epsilon a^\mu}}
= F(x) + \epsilon \PD{\lr{x^\mu + \epsilon a^\mu}}{F} a^\mu.
\end{dmath}
The directional derivative is
\begin{dmath}\label{eqn:reciprocal:920}
\lim_{\epsilon \rightarrow 0}
\frac{F(x + \epsilon a) - F(x)}{\epsilon}
=
\lim_{\epsilon \rightarrow 0}\,
a^\mu
\PD{\lr{x^\mu + \epsilon a^\mu}}{F}
=
a^\mu
\PD{x^\mu}{F}
=
\lr{a^\nu \gamma_\nu} \cdot \gamma^\mu \PD{x^\mu}{F}
=
a \cdot \lr{ \gamma^\mu \partial_\mu } F.
\end{dmath}
\end{proof}
\section{Curvilinear bases.}
Curvilinear bases are the foundation of the fundamental theorem of multivector calculus.  This form of integral calculus is defined over parameterized surfaces (called manifolds) that satisfy some specific non-degeneracy and continuity requirements.

A parameterized vector \( x(u,v, \cdots w) \) can be thought of as tracing out a hypersurface (curve, surface, volume, ...), where the dimension of the hypersurface depends on the number of parameters.
At each point, a bases can be constructed from the differentials of the parameterized vector.  Such a basis is called the tangent space to the surface at the point in question.  Our curvilinear bases will be related to these differentials.  We will also be interested in a dual basis that is restricted to the span of the tangent space.  This dual basis will be called the reciprocal frame, and line the basis of the tangent space itself, also varies from point to point on the surface.

One and two parameter spaces are illustrated in \cref{fig:tangentSpaceSurface:tangentSpaceSurfaceFig1}.
%\cref{fig:oneParameterDifferentialArrows:oneParameterDifferentialArrowsFig1}.
%\imageFigure{../figures/GAelectrodynamics/bw/oneParameterDifferentialArrowsFig1}{One parameter curve, and some tangent vectors.}{fig:oneParameterDifferentialArrows:oneParameterDifferentialArrowsFig1}{0.2}
%\cref{fig:tangentSpaceSurface:tangentSpaceSurfaceFig1}.
%\imageFigure{../figures/GAelectrodynamics/bw/tangentSpaceSurfaceFig1}{Two parameter curve, with some tangent planes.}{fig:tangentSpaceSurface:tangentSpaceSurfaceFig1}{0.2}
\imageTwoFigures
{../figures/GAelectrodynamics/bw/oneParameterDifferentialArrowsFig1}
{../figures/GAelectrodynamics/bw/tangentSpaceSurfaceFig1}{One and two parameter curves, with illustration of tangent spaces.}
{fig:tangentSpaceSurface:tangentSpaceSurfaceFig1}
{scale=0.6}

The tangent space basis at a specific point of a two parameter
surface, \( x(u^0, u^1) \),
is illustrated in
\cref{fig:twoParameterDifferentialCov:twoParameterDifferentialCovFig1}.  The differential directions that span the tangent space are
\begin{equation}\label{eqn:reciprocal:1040}
\begin{aligned}
d\Bx_0 &= \PD{u^0}{x} du^0 \\
d\Bx_1 &= \PD{u^1}{x} du^1,
\end{aligned}
\end{equation}
and the tangent space itself is \( \Span\setlr{ d\Bx_0, d\Bx_1 } \).  We may form an oriented surface area element \( d\Bx_0 \wedge d\Bx_1 \) over this surface.
\imageFigure{../figures/GAelectrodynamics/twoParameterDifferentialCovFig1}{Two parameter surface.}{fig:twoParameterDifferentialCov:twoParameterDifferentialCovFig1}{0.3}
Tangent spaces associated with 3 or more parameters cannot be easily visualized in three dimensions, but the idea generalizes algebraically without trouble.
\makedefinition{Tangent basis and space.}{dfn:reciprocal:100}{
Given a parameterization \( x = x(u^0, \cdots, u^N) \), where \( N < 4 \), the span of the vectors
\begin{equation*}
\Bx_\mu = \PD{u^\mu}{x},
\end{equation*}
is called the tangent space for the hypersurface associated with the parameterization, and it's basis is
\( \setlr{ \Bx_\mu } \).
%This subspace is called a manifold.
} % definition
Later we will see that parameterization constraints must be imposed, as not all surfaces generated by a set of parameterizations are useful for integration theory.  In particular, degenerate parameterizations for which the wedge products of the tangent space basis vectors are zero, or those wedge products cannot be inverted, are physically meaningful.  Properly behaved surfaces of this sort are called manifolds.

Having introduced curvilinear coordinates associated with a parameterization, we can now determine the form of the gradient with respect to a parameterization of spacetime.
\maketheorem{Gradient, curvilinear representation.}{thm:reciprocal:940}{
Given a spacetime parameterization \( x = x(u^0, u^1, u^2, u^3) \), the gradient with respect to the parameters \( u^\mu \) is
\begin{equation*}
\grad = \Bx^\mu
	\PD{u^\mu}{},
\end{equation*}
where
\begin{equation*}
\Bx^\mu = \grad u^\mu.
\end{equation*}
The vectors \( \Bx^\mu \) are called the reciprocal frame vectors, and the
ordered set \( \setlr{ \Bx^0, \Bx^1, \Bx^2, \Bx^3 } \) is called the reciprocal basis.
} % theorem
\begin{proof}
This follows by application of the chain rule.
\begin{dmath}\label{eqn:reciprocal:960}
\grad F
=
\gamma^\alpha \PD{x^\alpha}{F}
=
\gamma^\alpha
\PD{x^\alpha}{u^\mu}
\PD{u^\mu}{F}
=
\lr{ \grad u^\mu } \PD{u^\mu}{F}
=
\Bx^\mu \PD{u^\mu}{F}.
\end{dmath}
\end{proof}
\maketheorem{Reciprocal relationship.}{thm:reciprocal:120}{
The vectors \( \Bx^\mu = \grad u^\mu \), and \( \Bx_\mu = \PDi{u^\mu}{x} \) satisfy the reciprocal relationship
\begin{equation*}
   \Bx^\mu \cdot \Bx_\nu = {\delta^\mu}_\nu.
\end{equation*}
} % theorem
\begin{proof}
\begin{dmath}\label{eqn:reciprocal:1020}
   \Bx^\mu \cdot \Bx_\nu
   =
   \grad u^\mu \cdot
   \PD{u^\nu}{x}
   =
   \lr{
      \gamma^\alpha \PD{x^\alpha}{u^\mu}
   }
   \cdot
   \lr{
      \PD{u^\nu}{x^\beta} \gamma_\beta
   }
   =
   {\delta^\alpha}_\beta \PD{x^\alpha}{u^\mu}
      \PD{u^\nu}{x^\beta}
   =
   \PD{x^\alpha}{u^\mu} \PD{u^\nu}{x^\alpha}
   =
   \PD{u^\nu}{u^\mu}
   =
   {\delta^\mu}_\nu
.
\end{dmath}
\end{proof}
\section{REWRITE MARKER II.}

\makedefinition{Hypervolume elements.}{dfn:reciprocal:1060}{
Wedge products of the differentials that lie along each of the tangent basis directions
\begin{equation*}
d\Bx_\mu = \Bx_\mu du^\mu, \qquad \mbox{(no sum)},
\end{equation*}
can be used to form line, surface, volume, and hypervolume elements
\begin{equation*}
\begin{aligned}
d^1\Bx &= d\Bx_0 = \Bx_0 du^0 \\
d^2\Bx &= d\Bx_0 \wedge d\Bx_1 = \lr{\Bx_0 \wedge \Bx_1} du^0 du^1 \\
d^3\Bx &= d\Bx_0 \wedge d\Bx_1 \wedge d\Bx_2 = \lr{\Bx_0 \wedge \Bx_1 \wedge \Bx_2 } du^0 du^1 du^2 \\
d^4\Bx &= d\Bx_0 \wedge d\Bx_1 \wedge d\Bx_2 \wedge d\Bx_3 = \lr{\Bx_0 \wedge \Bx_1 \wedge \Bx_2 \wedge \Bx_3 } du^0 du^1 du^2 du^3.
\end{aligned}
\end{equation*}
%will be of interest when formulating the fundamental theorem of geometric algebra.
} % definition
For such hypervolume elements to be meaningful, we must impose a non-degeneracy constraint, and require that the
%In particular, the space must be non-degenerate, which means that the
volume elements above are non-zero (the Jacobian's of the partials are not zero.)  This non-zero constraint is required to ensure that the orientation of the volume elements do not change sign (as in differential forms, we do not take the absolute value of any Jacobians.)
We must also require that these volume elements are invertible, since non-invertible null vectors, bivectors, and trivectors,
are possible in our non-Euclidean space.
The parameterized hypersurfaces that we integrate over, when augmented with these additional constraints, are referred to as manifolds.

Consider the following example of a degenerate parameterization.
\makeproblem{Degenerate surface parameterization.}{problem:reciprocal:480}{
Given a spacetime plane parameterization \( x(u,v) = u \Ba + v \Bb \), where
\begin{dmath}\label{eqn:reciprocal:480}
	a = \gamma_0 + \gamma_1 + \gamma_2 + \gamma_3,
\end{dmath}
\begin{dmath}\label{eqn:reciprocal:500}
	b = \gamma_0 - \gamma_1 + \gamma_2 - \gamma_3,
\end{dmath}
show that this is a degenerate parameterization, and find the bivector that represents the tangent space.
Are these vectors lightlike, spacelike, or timelike?  Comment on whether this parameterization represents a physically relevant spacetime surface.
} % problem
\makeanswer{problem:reciprocal:480}{
To characterize the vectors, we square them
\begin{equation}\label{eqn:reciprocal:1080}
a^2 = b^2 =
\gamma_0^2 +
\gamma_1^2 +
\gamma_2^2 +
\gamma_3^2
=
1 - 3
= -2,
\end{equation}
so \( a, b \) are both spacelike vectors.  The tangent space is clearly just \( \Span \setlr{ a, b } = \Span \setlr{ e, f }\) where
\begin{equation}\label{eqn:reciprocal:1100}
\begin{aligned}
e &= \gamma_0 + \gamma_2 \\
f &= \gamma_1 + \gamma_3.
\end{aligned}
\end{equation}
Observe that \( a = e + f, b = e - f \), and that both \( e, f \) are lightlike (\( e^2 = f^2 = 0 \).)
The bivector for the tangent plane is
\begin{dmath}\label{eqn:reciprocal:1120}
\gpgradetwo{
a b
}
=
\gpgradetwo{
(e + f) (e - f)
}
=
\gpgradetwo{
e^2 - f^2 - 2 e f
}
= -2 e f,
\end{dmath}
where
\begin{dmath}\label{eqn:reciprocal:1140}
e f = \gamma_{01} + \gamma_{21} + \gamma_{23} + \gamma_{03}.
\end{dmath}
Because \( e, f \) are both lightlike (zero square), the bivector \( e f \) also squares to zero (compute this if in doubt),
which shows that the parameterization is degenerate.

Despite neither \( a, b \) being lightlike, the parameterization can also be expressed as
\begin{dmath}\label{eqn:reciprocal:1160}
x(u,v)
= u ( e + f ) + v ( e - f )
= (u + v) e + (u - v) f,
\end{dmath}
a linear combination of a pair of lightlike vectors.  This is clearly not a physically meaningful spacetime surface.
} % answer

\EndArticle
%\EndNoBibArticle
