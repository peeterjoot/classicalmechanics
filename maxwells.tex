%
% Copyright © 2020 Peeter Joot.  All Rights Reserved.
% Licenced as described in the file LICENSE under the root directory of this GIT repository.
%
%{
\input{../latex/blogpost.tex}
\renewcommand{\basename}{maxwells}
%\renewcommand{\dirname}{notes/phy1520/}
\renewcommand{\dirname}{notes/ece1228-electromagnetic-theory/}
%\newcommand{\dateintitle}{}
%\newcommand{\keywords}{}

\input{../latex/peeter_prologue_print2.tex}

\PassOptionsToPackage{answerdelayed}{exercise}

% proof:
\usepackage{amsthm}
\usepackage{macros_cal} % \LL
\usepackage{peeters_layout_exercise}
\usepackage{peeters_braket}
\usepackage{peeters_figures}
\usepackage{siunitx}
\usepackage{verbatim}
%\usepackage{mhchem} % \ce{}
%\usepackage{macros_bm} % \bcM
%\usepackage{macros_qed} % \qedmarker
%\usepackage{txfonts} % \ointclockwise

\beginArtNoToc

\generatetitle{Maxwell's equation using geometric algebra Lagrangian.}
%\chapter{XXX}
%\label{chap:maxwells}
\section{Motivation.}
In my classical mechanics notes, I've got computations of Maxwell's equation (singular in it's geometric algebra form) from a Lagrangian in various ways (using a tensor, scalar and multivector Lagrangians), but all of these seem more convoluted than they should be.  Here's a new derivation, starting with the action principle for field variables.
\section{Field action.}
\maketheorem{Relativistic Euler-Lagrange field equations.}{thm:maxwells:40}{
Let \( \phi \rightarrow \phi + \delta \phi \) be any variation of the field, such that the variation
\( \delta \phi = 0 \) vanishes at the boundaries of the action integral
\begin{equation*}
S = \int d^4 x \LL(\phi, \partial_\nu \phi).
\end{equation*}
The extreme value of the action is found when the Euler-Lagrange equations
\begin{equation*}
0 = \PD{\phi}{\LL} - \partial_\nu \PD{(\partial_\nu \phi)}{\LL},
\end{equation*}
are satisfied.  For a Lagrangian with multiple field variables, there will be one such equation for each field.
} % theorem
\begin{proof}
To ease the visual burden, designate the variation of the field by \( \delta \phi = \epsilon \), and perform a first order expansion of the varied Lagrangian
\begin{dmath}\label{eqn:maxwells:20}
\LL \rightarrow
\LL(\phi + \epsilon, \partial_\nu (\phi + \epsilon))
=
\LL(\phi, \partial_\nu \phi)
+
\PD{\phi}{\LL} \epsilon +
\PD{(\partial_\nu \phi)}{\LL} \partial_\nu \epsilon.
\end{dmath}
The variation of the Lagrangian is
\begin{dmath}\label{eqn:maxwells:40}
\delta \LL =
\PD{\phi}{\LL} \epsilon +
\PD{(\partial_\nu \phi)}{\LL} \partial_\nu \epsilon
=
\PD{\phi}{\LL} \epsilon +
\partial_\nu \lr{ \PD{(\partial_\nu \phi)}{\LL} \epsilon }
-
\epsilon \partial_\nu \PD{(\partial_\nu \phi)}{\LL},
\end{dmath}
which we may plug into the action integral to find
\begin{dmath}\label{eqn:maxwells:60}
   \delta S =
   \int d^4 x \epsilon \lr{
   \PD{\phi}{\LL}
   -
   \partial_\nu \PD{(\partial_\nu \phi)}{\LL}
}
+
   \int d^4 x
\partial_\nu \lr{ \PD{(\partial_\nu \phi)}{\LL} \epsilon }.
\end{dmath}
The last integral can be evaluated along the \( dx^\nu \) direction, leaving
\begin{dmath}\label{eqn:maxwells:80}
   \int d^3 x
   \evalbar{ \PD{(\partial_\nu \phi)}{\LL} \epsilon }{\Delta x^\nu},
\end{dmath}
where \( d^3 x = dx^\alpha dx^\beta dx^\gamma \) is the product of differentials that does not include \( dx^\nu \).  By construction, \( \epsilon \) vanishes on the boundary of the action integral so \cref{eqn:maxwells:80} is zero.  The action takes its extreme value when
\begin{dmath}\label{eqn:maxwells:100}
0 = \delta S
=
\int d^4 x \epsilon \lr{
   \PD{\phi}{\LL}
   -
   \partial_\nu \PD{(\partial_\nu \phi)}{\LL}
}.
\end{dmath}
The proof is complete after noting that this must hold for all variations of the field \( \epsilon \), which means that we must have
\begin{dmath}\label{eqn:maxwells:120}
0  =
   \PD{\phi}{\LL}
   -
   \partial_\nu \PD{(\partial_\nu \phi)}{\LL}.
\end{dmath}
\end{proof}
%}
Armed with the Euler-Lagrange equations, we can apply them to the Maxwell's equation Lagrangian.
\maketheorem{Maxwell's equation Lagrangian.}{thm:maxwells:140}{
Application of the Euler-Lagrange equations to the Lagrangian
\begin{equation*}
\LL = - \frac{\epsilon_0 c}{2} F \cdot F + J \cdot A,
\end{equation*}
where \( F = \grad \wedge A \), yields the vector portion of Maxwell's equation
\begin{equation*}
\grad \cdot F = \inv{\epsilon_0 c} J,
\end{equation*}
which implies
\begin{equation*}
\grad F = \inv{\epsilon_0 c} J.
\end{equation*}
This is Maxwell's equation.
} % definition
\begin{proof}
Let's take advantage of the Lagrangian linearity, and apply the Euler-Lagrange equations separately to the kinetic portion of the Lagrangian
\begin{dmath}\label{eqn:maxwells:140}
\LL_1 = - \frac{\epsilon_0 c}{2} F \cdot F,
\end{dmath}
and the interaction portion
\begin{dmath}\label{eqn:maxwells:160}
\LL_2 = J \cdot A.
\end{dmath}
Let's write
\begin{dmath}\label{eqn:maxwells:180}
\delta^\nu = \PD{A_\nu}{} - \partial_\mu \PD{(\partial_\mu A_\nu)}{}.
\end{dmath}
As the interaction Lagrangian has only direct dependence on \( A \), we have
\begin{dmath}\label{eqn:maxwells:200}
\delta^\nu \LL_2
=
\PD{A_\nu}{ A \cdot J }
=
\PD{A_\nu}{ } A_\mu J^\mu
=
J^\nu.
\end{dmath}
For the kinetic Lagrangian we only have the second order contribution
\begin{dmath}\label{eqn:maxwells:220}
\delta^\nu \LL_1
=
- \frac{\epsilon_0 c}{2} \lr{
   (\delta^\nu F) \cdot F
   +
   F \cdot (\delta^\nu F)
}
=
- \epsilon_0 c (\delta^\nu F) \cdot F.
\end{dmath}
Here we use the fact that for any two bivectors \( A \cdot B + B \cdot A = 2 A \cdot B \).
\begin{dmath}\label{eqn:maxwells:240}
\delta^\nu F
=
- \partial_\mu \PD{(\partial_\mu A_\nu)}{F}
=
- \partial_\mu \PD{(\partial_\mu A_\nu)}{ } \gamma^\alpha \wedge \gamma^\beta \partial_\alpha A_\beta
=
- \partial_\mu \gamma^\mu \wedge \gamma^\nu
=
(\gamma^\nu \wedge \grad),
\end{dmath}
so
\begin{equation}\label{eqn:maxwells:260}
0
= \delta^\nu \LL
= J^\nu - \epsilon_0 c (\gamma^\nu \wedge \grad) \cdot F.
\end{equation}
This expansion has been a little bit cavalier in the handling of operator quantities, but is correct provided we allow the gradient to act bidirectionally in some of the intermediate steps (without changing the position of any multivector factors in the applications of the partials.)  Spelled out explicitly, this was a requirement for the gradient operator that resulted from the application of \( \delta^\nu \) to act as follows
\begin{dmath}\label{eqn:maxwells:380}
   X \lrgrad Y
   =
   X (\rgrad Y) +
   (X \lgrad) Y
   =
   X \gamma^\mu (\partial_\mu Y)
   +
   (\partial_\mu X) \gamma^\mu Y.
\end{dmath}
Should the reader not be comfortable with this shortcut, a full expansion of \( F \cdot F \) in coordinates should demonatrate why this works.

We now expand the dot product of \cref{eqn:maxwells:260} as a scalar selection to eliminate the wedge
\begin{dmath}\label{eqn:maxwells:280}
(\gamma^\nu \wedge \grad) \cdot F
=
\gpgradezero{ (\gamma^\nu \wedge \grad) F }
=
\gpgradezero{ \gamma^\nu \grad F }
-
\cancel{ \gpgradezero{ (\gamma^\nu \cdot \grad) F } }
=
\gpgradezero{ \gamma^\nu (\grad \cdot F + \grad \wedge F) }.
=
\gamma^\nu \cdot (\grad \cdot F).
\end{dmath}
Contracting with \( \gamma_\nu \) we have
\begin{dmath}\label{eqn:maxwells:300}
0
=
\gamma_\nu (J^\nu - \epsilon_0 c  \gamma^\nu \cdot (\grad \cdot F))
=
J - \epsilon_0 c \grad \cdot F.
\end{dmath}
Finally, note that
\begin{dmath}\label{eqn:maxwells:320}
\grad F
=
\grad \cdot F
+
\grad \wedge F,
\end{dmath}
but
\begin{equation}\label{eqn:maxwells:360}
\grad \wedge F
=
\grad \wedge (\grad \wedge A)
=
0,
\end{equation}
so
\begin{dmath}\label{eqn:maxwells:340}
\grad F = \inv{ \epsilon_0 c } J.
\end{dmath}
\end{proof}

%\EndArticle
\EndNoBibArticle
